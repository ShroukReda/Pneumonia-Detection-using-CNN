# -*- coding: utf-8 -*-
"""Pne_VS_Normal86%.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RyRqTF7nFPOdEDxaZ9m7xw1YfGuYlcj7

# **Access data from kaggle**
"""

!pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

cd /content

!kaggle datasets list

!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

from zipfile import ZipFile

file_name = "/content/chest-xray-pneumonia.zip"

# opening the zip file in read me mode
with ZipFile(file_name, 'r') as zip :
  print("Extracting the files...")
  zip.extractall()
  print("Done")

"""# **Exploring data**"""

import os
#TRAIN
PTrainList=os.listdir("/content/chest_xray/train/PNEUMONIA")
NTrainList=os.listdir("/content/chest_xray/train/NORMAL")
print("P",len(PTrainList))
print("N",len(NTrainList))

#VAL
PValList=os.listdir("/content/chest_xray/val/PNEUMONIA")
NValList=os.listdir("/content/chest_xray/val/NORMAL")
print("P",len(PValList))
print("N",len(NValList))

"""# **Data Augmentation**"""

from skimage.filters import threshold_yen
from skimage.exposure import rescale_intensity
from skimage.io import imread, imsave
from google.colab.patches import cv2_imshow
import cv2
import imutils

IM=NTrainList[0]
IM="/content/chest_xray/train/NORMAL/"+IM
img = cv2.imread(IM)
cv2_imshow(img)
# Use Flip code 1 to flip horizontally 
#img = cv2.flip(img, 1) 
#alpha = 1 # Contrast control (1.0-3.0)
#beta = 50 # Brightness control (0-100)
#img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)
#print("_____________")
cv2_imshow(img)
#imsave(IM+'Aug1.jpeg', img)

img = imutils.rotate(img, 20)
alpha = 1 # Contrast control (1.0-3.0)
beta = 30 # Brightness control (0-100)
img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)
print("_____________")
cv2_imshow(img)
#imsave(IM+'Aug2.jpeg', img)

from scipy import ndimage
from google.colab.patches import cv2_imshow
from scipy import misc
import imgaug.augmenters as iaa

import cv2
IM=NTrainList[0]
IM="/content/chest_xray/train/NORMAL/"+IM
img = cv2.imread(IM)
cv2_imshow(img)

contrast=iaa.GammaContrast(gamma=2.0)
contrast_image =contrast.augment_image(img)
cv2_imshow(contrast_image)
scale_im=iaa.Affine(scale={"x": (1.5, 1.0), "y": (1.5, 1.0)})
scale_image =scale_im.augment_image(contrast_image)
cv2_imshow(scale_image)

from skimage.filters import threshold_yen
from skimage.exposure import rescale_intensity
from skimage.io import imread, imsave
import cv2
import imutils
from scipy import ndimage
from scipy import misc

#AUG for NORMAL only
c=0
for IM in NTrainList:
  img = cv2.imread("/content/chest_xray/train/NORMAL/"+IM)
  if c%2==0: #using different 2 aug. based on index
    # Use Flip code 1 to flip horizontally 
    img = cv2.flip(img, 1) 
    alpha = 1 # Contrast control (1.0-3.0)
    beta = 50 # Brightness control (0-100)
    img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)
    imsave("/content/chest_xray/train/NORMAL/"+IM+'Aug1.jpeg', img)
  else:
    img = imutils.rotate(img, 20)
    alpha = 1 # Contrast control (1.0-3.0)
    beta = 30 # Brightness control (0-100)
    img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)
    imsave("/content/chest_xray/train/NORMAL/"+IM+'Aug2.jpeg', img)
  print(IM)
  print(c)
  c+=1

#AFTER AUG
import os
#TRAIN
PTrainList=os.listdir("/content/chest_xray/train/PNEUMONIA")
NTrainList=os.listdir("/content/chest_xray/train/NORMAL")
print("P",len(PTrainList))
print("N",len(NTrainList))

#VAL
PValList=os.listdir("/content/chest_xray/val/PNEUMONIA")
NValList=os.listdir("/content/chest_xray/val/NORMAL")
print("P",len(PValList))
print("N",len(NValList))

#2nd AUG
from scipy import ndimage
from google.colab.patches import cv2_imshow
from scipy import misc
import imgaug.augmenters as iaa
import cv2
from skimage.io import imread, imsave

c=0
for IM in NTrainList:
  img = cv2.imread("/content/chest_xray/train/NORMAL/"+IM)
  if c%3==0: #using different 2 aug. based on index
    contrast=iaa.GammaContrast(gamma=2.0)
    contrast_image =contrast.augment_image(img)
    #cv2_imshow(contrast_image)
    scale_im=iaa.Affine(scale={"x": (1.5, 1.0), "y": (1.5, 1.0)})
    img =scale_im.augment_image(contrast_image)
    imsave("/content/chest_xray/train/NORMAL/"+IM+'Aug3.jpeg', img)
    print(IM)
    print(c)
  c+=1

#AFTER 2nd AUG
import os
#TRAIN
PTrainList=os.listdir("/content/chest_xray/train/PNEUMONIA")
NTrainList=os.listdir("/content/chest_xray/train/NORMAL")
print("P",len(PTrainList))
print("N",len(NTrainList))

#VAL
PValList=os.listdir("/content/chest_xray/val/PNEUMONIA")
NValList=os.listdir("/content/chest_xray/val/NORMAL")
print("P",len(PValList))
print("N",len(NValList))

"""# **Data Preparation**"""

import numpy as np
import os
import random
NTrainPath="/content/chest_xray/train/NORMAL"
PTrainPath="/content/chest_xray/train/PNEUMONIA"
TrainData=[]
for N in os.listdir(NTrainPath):
  TrainData.append(["/content/chest_xray/train/NORMAL/"+N,0])
for P in os.listdir(PTrainPath):
  TrainData.append(["/content/chest_xray/train/PNEUMONIA/"+P,1])
print(len(TrainData))
print(TrainData[0])
print(TrainData[len(TrainData)-1])
#Shuffle data
random.shuffle(TrainData)
print("After Shuffle")
print(len(TrainData))
print(TrainData[0])
print(TrainData[len(TrainData)-1])
print(TrainData[1300])

import cv2
from keras.utils import to_categorical

# ValidationData
ValData=[]
Vlabels=[]
for img in os.listdir("/content/chest_xray/val/NORMAL"):
    img = cv2.imread("/content/chest_xray/val/NORMAL/"+img)  
    img = cv2.resize(img, (150,150))
    if img.shape[2] ==1:
        img = np.dstack([img, img, img])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype(np.float32)/255.
    label = to_categorical(0, num_classes=2)
    ValData.append(img)
    Vlabels.append(label)
                      
for img in os.listdir("/content/chest_xray/val/PNEUMONIA"):
    img = cv2.imread("/content/chest_xray/val/PNEUMONIA/"+img)
    img = cv2.resize(img, (150,150))
    if img.shape[2] ==1: #if grayscale
        img = np.dstack([img, img, img]) #convert into 3 channels.
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype(np.float32)/255.
    label = to_categorical(1, num_classes=2)
    ValData.append(img)
    Vlabels.append(label)
    
# Convert the list into numpy arrays
ValData = np.array(ValData)
Vlabels = np.array(Vlabels)

print(ValData.shape)
print(Vlabels.shape)

"""# **Data generators**"""

def Tgenerator(data,batch_size):
    #c=0
    while True:
      for start in range(0, len(TrainData),batch_size):
          count = 0
          batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)
          batch_labels = np.zeros((batch_size,2), dtype=np.float32)
          end = min(start + batch_size, len(TrainData))
          for i in range(start, end):
            img_name = data[i][0]
            label = data[i][1]
            #print(count)
            #print(label,img_name)
            # one hot encoding
            encoded_label = to_categorical(label, num_classes=2)
            # read the image and resize
            img = cv2.imread(img_name)
            img = cv2.resize(img, (224,224))
            
            # check if it's grayscale
            if img.shape[2]==1:
                img = np.dstack([img, img, img]) #convert to 3 channels.
            
            # cv2 reads in BGR mode by default
            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            # normalize the image pixels
            orig_img = img.astype(np.float32)/255.
            
            batch_data[count] = orig_img
            batch_labels[count] = encoded_label
            count+=1
          yield  batch_data, batch_labels

from keras import backend as K
#define another metrices
def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

training_dir="/content/chest_xray/train"
training_generator=ImageDataGenerator(rescale=1/255,featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.2, # Randomly zoom image 
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip = False,  # randomly flip images
        vertical_flip=False)
train_generator=training_generator.flow_from_directory(training_dir,target_size=(224,224),batch_size=16,class_mode='binary')


validation_dir="/content/chest_xray/val"
validation_generator=ImageDataGenerator(rescale=1/255)
val_generator=validation_generator.flow_from_directory(validation_dir,target_size=(224,224),batch_size=16,class_mode='binary')

"""# **Building CNN Model**"""

import glob
import h5py
import shutil
import imgaug as aug
import numpy as np
import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mimg
import imgaug.augmenters as iaa
from os import listdir, makedirs, getcwd, remove
from os.path import isfile, join, abspath, exists, isdir, expanduser
from PIL import Image
from pathlib import Path
from skimage.io import imread
from skimage.transform import resize
from keras.models import Sequential, Model
from keras.applications.vgg16 import VGG16, preprocess_input
from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D
from keras.layers import GlobalMaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.layers.merge import Concatenate
from keras.models import Model
from keras.optimizers import Adam, SGD, RMSprop
from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from keras.applications import VGG19
from keras import applications
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.optimizers import RMSprop, SGD
from keras.models import Model, Sequential
import matplotlib.pyplot as plt
from keras.layers import Input
from keras import models
from keras import layers
from keras import optimizers
from keras.preprocessing import image
from tensorflow.python.keras import regularizers
from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping

input_tensor = Input(shape=(224, 224, 3))
vgg_conv = VGG19(weights='imagenet',
                               include_top=False,
                               input_tensor=input_tensor)
# Freeze the layers except the last 2 layers
for layer in vgg_conv.layers[:-2]:
    layer.trainable = False
 
# Check the trainable status of the individual layers
for layer in vgg_conv.layers:
    print(layer, layer.trainable)

# Create the model
model = models.Sequential()
# Add the vgg convolutional base model
model.add(vgg_conv)
model.add(layers.Dropout(0.5))
model.add(SeparableConv2D(128, (3,3), activation='relu', padding='same'))
model.add(SeparableConv2D(128, (3,3), activation='relu', padding='same'))
model.add(MaxPooling2D((2,2)))

model.add(SeparableConv2D(256, (3,3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(SeparableConv2D(256, (3,3), activation='relu', padding='same'))
#model.add(BatchNormalization())

#model.add(SeparableConv2D(512, (3,3), activation='relu', padding='same')) 
#model.add(SeparableConv2D(512, (3,3), activation='relu', padding='same')) #best without that 85
model.add(MaxPooling2D((2,2)))



model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.7))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

model.summary()

opt = optimizers.Adam(lr=0.0001, decay=1e-5)
es = EarlyStopping(patience=5)
chkpt = ModelCheckpoint(filepath='BestModel', save_best_only=True, save_weights_only=True)
model.compile(loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m],optimizer=opt)

batch_size = 16

# Get a train data generator
train_data_gen = Tgenerator(TrainData,batch_size)

# Define the number of training steps
steps = len(TrainData)//batch_size
print(steps)

# Fit the model
history = model.fit_generator(train_data_gen, epochs=10, steps_per_epoch=steps,validation_data=(ValData, Vlabels),callbacks=[es, chkpt],class_weight={0:1.0, 1:0.4}) #save the best one

# summarize history for accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""# **Testing**"""

# Preparing test data
import os
import cv2
test_data = []
test_labels = []

for img in os.listdir("/content/chest_xray/test/NORMAL"):
    img = cv2.imread("/content/chest_xray/test/NORMAL/"+img)
    img = cv2.resize(img, (224,224))
    if img.shape[2] ==1:
        img = np.dstack([img, img, img])
    else:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype(np.float32)/255.
    label = to_categorical(0, num_classes=2)
    test_data.append(img)
    test_labels.append(label)
                      
for img in os.listdir("/content/chest_xray/test/PNEUMONIA"):
    img = cv2.imread("/content/chest_xray/test/PNEUMONIA/"+img)
    img = cv2.resize(img, (224,224))
    if img.shape[2] ==1:
        img = np.dstack([img, img, img])
    else:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype(np.float32)/255.
    label = to_categorical(1, num_classes=2)
    test_data.append(img)
    test_labels.append(label)
    

test_data = np.array(test_data)
test_labels = np.array(test_labels)

print("Total number of test examples: ", test_data.shape)
print("Total number of labels:", test_labels.shape)

model.load_weights("/content/BestModel1/BestModel")

preds = model.predict(test_data, batch_size=16)
preds = np.argmax(preds, axis=-1)

# Original labels
orig_test_labels = np.argmax(test_labels, axis=-1)

print(orig_test_labels.shape)
print(preds.shape)

#Total Test Accuracy
Acc=0
for i in range(len(preds)):
  if preds[i]==orig_test_labels[i]:
    Acc+=1
print(Acc/624)

#Confusion Matrix
cm  = confusion_matrix(orig_test_labels, preds)
plt.figure()
plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, cmap=plt.cm.BuPu)
plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=18)
plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=18)
plt.show()

L=["Normal","Pneumonia"]
img = cv2.imread("/content/chest_xray/test/NORMAL/IM-0009-0001.jpeg")
img = cv2.resize(img, (224,224))
if img.shape[2] ==1:
    img = np.dstack([img, img, img])
else:
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.axis('off')
plt.imshow(img)
img = np.expand_dims(img, axis=0)
img = img.astype(np.float32)/255.
label = to_categorical(0, num_classes=2)
PredictedLabel = np.argmax(model.predict(img))
#print(PredictedLabel)
print("PredictedLabel is: ",L[PredictedLabel])
print("TrueLabel is:",L[np.argmax(label)])

img = cv2.imread("/content/chest_xray/test/PNEUMONIA/person100_bacteria_475.jpeg")
img = cv2.resize(img, (224,224))
if img.shape[2] ==1:
    img = np.dstack([img, img, img])
else:
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.axis('off')
plt.imshow(img)
img = np.expand_dims(img, axis=0)
img = img.astype(np.float32)/255.
label = to_categorical(1, num_classes=2)
PredictedLabel = np.argmax(model.predict(img))
#print(PredictedLabel)
print("PredictedLabel is: ",L[PredictedLabel])
print("TrueLabel is:",L[np.argmax(label)])

# Calculate Precision and Recall
tn, fp, fn, tp = cm.ravel()

precision = tp/(tp+fp)
recall = tp/(tp+fn)

print("Recall of the model is {:.2f}".format(recall))
print("Precision of the model is {:.2f}".format(precision))

import shutil
shutil.make_archive('/content/Pne_VS_Normal', 'zip', '/content/BestModel1')